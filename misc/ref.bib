% My Reference

% chapter 1
% 开题报告ref
@article{唐振韬2017深度强化学习进展,
  title={深度强化学习进展:从AlphaGo到AlphaGo Zero},
  author={唐振韬 and 邵坤 and 赵冬斌 and 朱圆恒},
  journal={控制理论与应用},
  volume={34},
  number={12},
  pages={18},
  year={2017},
}
@article{2017Deep,
  title={Deep Reinforcement Learning: An Overview},
  author={ Li, Y. },
  journal={arXiv preprint arXiv:1701.07274},
  year={2017},
}
@article{2017Review,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{2019AutoDrive,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE access},
  volume={8},
  pages={58443--58469},
  year={2020},
  publisher={IEEE}
}
@inproceedings{2015DeepDriving,
  title={Deepdriving: Learning affordance for direct perception in autonomous driving},
  author={Chen, Chenyi and Seff, Ari and Kornhauser, Alain and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2722--2730},
  year={2015}
}
@article{1989Alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}
@article{2016End,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}
@article{1996Evolution,
  title={Evolution of an artificial neural network based autonomous land vehicle controller},
  author={Baluja, Shumeet},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={26},
  number={3},
  pages={450--463},
  year={1996},
  publisher={IEEE}
}
@article{2017DRL_end_to_end,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}
@inproceedings{2016Target,
  title={Target-driven visual navigation in indoor scenes using deep reinforcement learning},
  author={Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3357--3364},
  year={2017},
  organization={IEEE}
}
@article{2017Deepzhao,
  title={Deep reinforcement learning with visual attention for vehicle classification},
  author={Zhao, Dongbin and Chen, Yaran and Lv, Le},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={9},
  number={4},
  pages={356--367},
  year={2016},
  publisher={IEEE}
}
@inproceedings{2021Learning,
  title={Learning to drive from a world on rails},
  author={Chen, Dian and Koltun, Vladlen and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15590--15599},
  year={2021}
}
@article{2018Recurrent,
  title={Recurrent world models facilitate policy evolution},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
% DQN相关
@inproceedings{2012Autonomous,
  title={Autonomous reinforcement learning on raw visual input data in a real world application},
  author={Lange, Sascha and Riedmiller, Martin and Voigtl{\"a}nder, Arne},
  booktitle={The 2012 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2012},
  organization={IEEE}
}
@article{2013DQN,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@inproceedings{2015DDQN,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}
@inproceedings{2016DuelingDQN,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={1995--2003},
  year={2016},
  organization={PMLR}
}
@article{2017Obstacle,
  title={Obstacle avoidance for self-driving vehicle with reinforcement learning},
  author={Zong, Xiaopeng and Xu, Guoyan and Yu, Guizhen and Su, Hongjie and Hu, Chaowei},
  journal={SAE International Journal of Passenger Cars-Electronic and Electrical Systems},
  volume={11},
  number={1},
  pages={28--38},
  year={2018},
  publisher={SAE International}
}

% chapter 2
% Markov decision processes
@article{monahan1982state,
  title={State of the art—a survey of partially observable Markov decision processes: theory, models, and algorithms},
  author={Monahan, George E},
  journal={Management science},
  volume={28},
  number={1},
  pages={1--16},
  year={1982},
  publisher={INFORMS}
}
% Q-learning
@article{1992Technical,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992},
  publisher={Springer}
}
% 强化学习证明收敛
@book{1998Reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  journal={Robotica},
  volume={17},
  number={2},
  pages={229--235},
  year={1999}
}
% 经验回放
@book{1992Reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1992},
  publisher={Carnegie Mellon University}
}
% Q值分解
@techreport{1993Advantage,
  title={Advantage updating},
  author={Baird III, Leemon C},
  year={1993},
  institution={WRIGHT LAB WRIGHT-PATTERSON AFB OH}
}

% chapter 3
% highway-env
@misc{highway-env,
  author = {Leurent, Edouard},
  title = {An Environment for Autonomous Driving Decision-Making},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/highway-env}},
}
% Metadrive
@article{li2021metadrive,
  title={MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning},
  author={Li, Quanyi and Peng, Zhenghao and Xue, Zhenghai and Zhang, Qihang and Zhou, Bolei},
  journal={arXiv preprint arXiv:2109.12674},
  year={2021}
}
% Carla
@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

% chapter 4
% Metadrive-DQN
@misc{metadrive-dqn,
  author = {Huang, Chenrui},
  title = {Metadrive-simulator Agent using DQN},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/HRex39/Metadrive-DQN}},
}
% Highway-Env-DQN
@misc{highway-env-dqn,
  author = {Huang, Chenrui},
  title = {Highway-Env Agent using DQN},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/HRex39/Highway-Env-DQN}},
}

% conclusion
% 2022ApolloRL
@article{2022ApolloRL,
  title={ApolloRL: a Reinforcement Learning Platform for Autonomous Driving},
  author={Gao, Fei and Geng, Peng and Guo, Jiaqi and Liu, Yuan and Guo, Dingfeng and Su, Yabo and Zhou, Jie and Wei, Xiao and Li, Jin and Liu, Xu},
  journal={arXiv preprint arXiv:2201.12609},
  year={2022}
}
% Myself
@inproceedings{chen2022real,
  title={Real-Time Motion Planning and Control for a Formula Student Driverless Car},
  author={Chen, Tairan and Gao, Xinyu and Huang, Chenrui and Li, Xiang and Yang, Shaokun and Gong, Hailong and Feng, Yunji},
  booktitle={Proceedings of China SAE Congress 2020: Selected Papers},
  pages={203--219},
  year={2022},
  organization={Springer}
}
