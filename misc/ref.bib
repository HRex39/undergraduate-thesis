% My Reference

% chapter 1
% 开题报告ref
@article{唐振韬2017深度强化学习进展,
  title={深度强化学习进展:从AlphaGo到AlphaGo Zero},
  author={唐振韬 and 邵坤 and 赵冬斌 and 朱圆恒},
  journal={控制理论与应用},
  volume={34},
  number={12},
  pages={18},
  year={2017},
}
@article{2017Deep,
  title={Deep Reinforcement Learning: An Overview},
  author={ Li, Y. },
  year={2017},
}
@article{2017Review,
  title={Review - Mastering the game of Go with deep neural networks and tree search},
  author={ Babbar, S. },
  year={2017},
}
@article{2019AutoDrive,
  title={A Survey of Autonomous Driving: Common Practices and Emerging Technologies},
  author={ Yurtsever, E.  and  Lambert, J.  and  Carballo, A.  and  Takeda, K. },
  year={2019},
}
@article{2015DeepDriving,
  title={DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving},
  author={ Chen, C.  and  Seff, A.  and  Kornhauser, A.  and  Xiao, J. },
  journal={IEEE},
  pages={2722-2730},
  year={2015},
}
@article{1989Alvinn,
  title={Alvinn: An Autonomous Land Vehicle in a Neural Network},
  author={ Pomerleau, D. A },
  journal={Morgan Kaufmann Publishers Inc.},
  year={1989},
}
@article{2016End,
  title={End to End Learning for Self-Driving Cars},
  author={ Bojarski, M.  and  Testa, D Del  and  Dworakowski, D.  and  Firner, B.  and  Flepp, B.  and  Goyal, P.  and  Jackel, L. D.  and  Monfort, M.  and  Muller, U.  and  Zhang, J. },
  year={2016},
}
@article{1996Evolution,
  title={Evolution of an artificial neural network based autonomous land vehicle controller},
  author={ Baluja, S. },
  journal={Systems Man & Cybernetics Part B Cybernetics IEEE Transactions on},
  volume={26},
  number={3},
  pages={450-463},
  year={1996},
}
@article{2017DRL_end_to_end,
  title={Deep Reinforcement Learning framework for Autonomous Driving},
  author={ Sallab, A.  and  Abdou, M.  and  Perot, E.  and  Yogamani, S. },
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70-76},
  year={2017},
}
@article{2016Target,
  title={Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning},
  author={ Zhu, Y.  and  Mottaghi, R.  and  Kolve, E.  and  Lim, J. J.  and  Gupta, A.  and  Fei-Fei, L.  and  Farhadi, A. },
  year={2016},
}
@article{2017Deep,
  title={Deep reinforcement learning with visual attention for vehicle classification},
  author={ Zhao, D.  and  Chen, Y.  and  Le, L. },
  journal={IEEE Transactions on Cognitive & Developmental Systems},
  volume={PP},
  number={4},
  pages={1-1},
  year={2017},
}
@article{2021Learning,
  title={Learning to drive from a world on rails},
  author={ Chen, D.  and  Koltun, V.  and P Krhenbühl},
  year={2021},
}
@article{2018Recurrent,
  title={Recurrent World Models Facilitate Policy Evolution},
  author={ Ha, D.  and  Schmidhuber, J. },
  year={2018},
}
% DQN相关
@inproceedings{2012Autonomous,
  title={Autonomous reinforcement learning on raw visual input data in a real world application},
  author={ Lange, S.  and  Riedmiller, M.  and  Voigtlander, A. },
  booktitle={International Joint Conference on Neural Networks},
  year={2012},
}
@article{2013DQN,
  title={Playing Atari with Deep Reinforcement Learning},
  author={ Chung, Jonathan },
  journal={Computer Science},
  year={2013},
}
@article{2015DDQN,
  title={Deep Reinforcement Learning with Double Q-learning},
  author={ Hasselt, Hado Van  and  Guez, Arthur  and  Silver, David },
  journal={Computer ence},
  year={2015},
}
@article{2016DuelingDQN,
  title={Dueling network architectures for deep reinforcement learning},
  author={ Freitas, Nando De  and  Lanctot, Marc  and  Hasselt, Hado Van  and  Hessel, Matteo  and  Schaul, Tom  and  Wang, Ziyu },
  year={2016},
}
@article{2017Obstacle,
  title={Obstacle Avoidance for Self-Driving Vehicle with Reinforcement Learning},
  author={ Zong, X.  and  Xu, G.  and  Yu, G.  and  Su, H.  and  Hu, C. },
  journal={SAE International Journal of Passenger Cars - Electronic and Electrical Systems},
  volume={11},
  number={1},
  pages={07-11-01-0003-},
  year={2017},
}

% chapter 2
% Q-learning
@article{1992Technical,
  title={Technical Note: Q-Learning},
  author={ Watkins, Cjch  and  Dayan, P. },
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={279-292},
  year={1992},
}
% 强化学习证明收敛
@book{1998Reinforcement,
  title={Reinforcement Learning:An Introduction},
  author={ Sutton, R.  and  Barto, A. },
  publisher={Reinforcement Learning:An Introduction},
  year={1998},
}
% 经验回放
@article{1992Reinforcement,
  title={Reinforcement Learning for Robots Using Neural Networks},
  author={ Lin, L. J },
  journal={Ph.d.thesis Carnegie Mellon University},
  year={1992},
}
% Q值分解
@article{1993Advantage,
  title={Advantage updating},
  author={ Iii, L. B. },
  journal={Advantage Updating},
  year={1993},
}
% highway-env
@misc{highway-env,
  author = {Leurent, Edouard},
  title = {An Environment for Autonomous Driving Decision-Making},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/highway-env}},
}
% Metadrive
