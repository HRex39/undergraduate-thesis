%%
% The BIThesis Template for Bachelor Graduation Thesis
%
% 北京理工大学毕业设计（论文）中英文摘要 —— 使用 XeLaTeX 编译
%
% Copyright 2020-2021 BITNP
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Feng Kaiyu.

% 中英文摘要章节
\zihao{-4}
\vspace*{-11mm}

\begin{center}
  \heiti\zihao{-2}\textbf{\thesisTitle}
\end{center}

\vspace*{2mm}

{\let\clearpage\relax \chapter*{\textmd{摘~~~~要}}}
\addcontentsline{toc}{chapter}{摘~~~~要}
\setcounter{page}{1}

\vspace*{1mm}

\setstretch{1.53}
\setlength{\parskip}{0em}

% 中文摘要正文从这里开始
自动驾驶系统保证了快捷、安全、高效的驾驶体验，实现自动驾驶避障需要自动驾驶决策和控制系统的紧密配合。随着近些年硬件系统和软件算法的提升，自动驾驶系统在决策和控制方面的安全性和稳定性越来越受到广泛的关注。自动驾驶决策和控制系统的设计涵盖自动化技术、传感器技术、智能控制技术，也是人工智能和机器学习的重要应用领域。一贯以来，实现自动驾驶的决策和控制系统需要构建大量的数学模型，依靠人工设计的算法从复杂环境中提取关键信息，因此降低自动驾驶决策和控制系统的复杂度一直是自动驾驶领域研究的重点方向之一。强化学习通过不断探索环境自主学习复杂的控制模型，深度学习与强化学习相结合形成的深度强化学习方法可实现端到端的决策与控制，逐渐成为自动驾驶领域的研究热点。

本文以实现端到端的自动驾驶决策器和控制器为研究目标，围绕两种不同复杂度的仿真环境，针对DQN及其改进算法搭建神经网络模型，验证实现了基于DQN及其改进算法的自动驾驶决策器和控制器，并就DQN及其改进算法开展了较为深入的研究。

研究进展和实验结果表明，本文设计实现的基于DQN及其改进算法的自动驾驶决策器和控制器均满足实验要求，达到了预期的控制效果，能够有效提高自动驾驶车辆在决策和控制中的鲁棒性。对于较为简单的网络结构，DQN特别是Double DQN算法由于其改进的动作选择和评估方法，能够获得更加稳定有效的行为策略。本文的成果为自动驾驶决策器和控制器的研究提供了借鉴和参考，也为复杂动力学模型问题的解决提供了新的思路和方法。

\vspace{4ex}\noindent\textbf{\heiti 关键词：自动驾驶避障；自动驾驶决策；控制器设计；DQN网络；深度强化学习；端到端驾驶}
\newpage

% 英文摘要章节
\vspace*{-2mm}

\begin{spacing}{0.95}
  \centering
  \heiti\zihao{3}\textbf{\thesisTitleEN}
\end{spacing}

\vspace*{17mm}

{\let\clearpage\relax \chapter*{
  \zihao{-3}\textmd{Abstract}\vskip -3bp}}
\addcontentsline{toc}{chapter}{Abstract}
\setcounter{page}{2}

\setstretch{1.53}
\setlength{\parskip}{0em}

% 英文摘要正文从这里开始
The Automatic Driving System ensures a fast, safe and efficient driving experience, and the implementation of Automatic Driving Obstacle Avoidance requires the cooperation of the automatic driving decision-making and control system. With the improvement of hardware systems and software algorithms in recent years, the safety and stability of Autonomous Driving Systems in decision-making and control have received more and more attention. The design of autonomous driving decision-making and control systems covers automation technology, sensor technology, intelligent control technology, and is also an important application area of ​​Artificial Intelligence and Machine Learning. It has always been necessary to build a large number of mathematical models to realize the decision-making and control system of autonomous driving, and rely on artificially designed algorithms to extract key information from complex environments. Therefore, reducing the complexity of autonomous driving decision-making and control systems has always been the focus of research in the field of autonomous driving. Reinforcement Learning learns complex control models autonomously by continuously exploring the environment. The Deep Reinforcement Learning method formed by the combination of Deep Learning and Reinforcement Learning can realize end-to-end decision-making and control, and has gradually become a research hotspot in the field of Autonomous Driving.

This paper aims to implement the end-to-end autonomous driving decision maker and controller. Focusing on two simulation environments with different complexity, a neural network model is built for DQN and its improved algorithm, and the automatic driving based on DQN and its improved algorithm is verified. The article also conducts more in-depth research on DQN and its improved algorithm. 

The research progress and experimental results show that the autonomous driving decision maker and controller based on DQN and its improved algorithm designed and implemented in this paper meet the experimental requirements, achieve the expected control effect, and can effectively improve the robustness of autonomous driving vehicles in decision-making and control. For simpler network structures, DQN, especially the Double DQN algorithm, can obtain more stable and effective behavior strategies due to its improved action selection and evaluation methods. The results of this paper provide reference for the research of automatic driving decision maker and controller, and also provide new ideas and methods for solving complex dynamic model problems.

\vspace{3ex}\noindent\textbf{Key Words: Automatic Driving Obstacle Avoidance; Automatic Driving Decision-Making; Controller Design; DQN Network; Reinforcement Learning; End-to-end Driving}
\newpage
